import ast
from langchain_core.messages import SystemMessage, HumanMessage
from core.state import AgentState
from config_factory import get_llm

def qa_node(state: AgentState):
    print("\nüêû [QA]: Szybka weryfikacja sk≈Çadni...")
    
    # Pobieramy ostatnio edytowany plik
    idx = state.get("current_file_index", 1) - 1
    files = state.get("project_files", [])
    
    if not files or idx < 0:
         # Co≈õ posz≈Ço nie tak, przepuszczamy
        return {"test_feedback": "PASSED"}

    current_file = files[-1] # Ostatni dodany
    code = current_file["content"]
    filename = current_file["name"]
    
    # 1. Test Sk≈Çadni (AST) - Wy≈Çapuje "gadanie" modelu
    try:
        ast.parse(code)
        print(f"   -> ‚úÖ Sk≈Çadnia {filename} poprawna.")
    except SyntaxError as e:
        error_msg = f"B≈ÇƒÖd sk≈Çadni w pliku {filename} linia {e.lineno}: {e.msg}. Prawdopodobnie model doda≈Ç tekst poza kodem."
        print(f"   -> ‚ùå {error_msg}")
        # Cofamy indeks, ≈ºeby Coder poprawi≈Ç ten sam plik
        return {
            "test_feedback": f"FAILED: {error_msg}",
            "current_file_index": idx # Cofka
        }

    # 2. (Opcjonalnie) Test Logiczny przez LLM - je≈õli chcesz byƒá super dok≈Çadny
    # Na razie pomi≈Ñmy to dla szybko≈õci, skoro problemem by≈Çy ≈õmieci w kodzie.
    
    return {"test_feedback": "PASSED"}