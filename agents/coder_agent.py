from langchain_core.messages import SystemMessage, HumanMessage
from core.state import AgentState
from config_factory import get_llm

def coder_node(state: AgentState):
    file_structure = state.get("file_structure", [])
    idx = state.get("current_file_index", 0)
    existing_files = state.get("project_files", [])
    
    # Zabezpieczenie przed wyj≈õciem poza zakres
    if idx >= len(file_structure):
        return {}

    current_filename = file_structure[idx]
    print(f"\nüë®‚Äçüíª [Coder]: Piszƒô plik {idx+1}/{len(file_structure)}: {current_filename}...")
    
    # Budujemy kontekst (pokazujemy mu kod plik√≥w, kt√≥re ju≈º stworzy≈Ç)
    context_files = ""
    for f in existing_files:
        context_files += f"\n--- PLIK: {f['name']} ---\n{f['content']}\n"
    
    llm = get_llm(model_role="coder")
    
    system_prompt = f"""Jeste≈õ Ekspertem Python. Piszesz kod projektu plik po pliku.
    
    TWOJE ZADANIE:
    Napisz zawarto≈õƒá pliku: '{current_filename}'.
    
    KONTEKST (Pliki ju≈º utworzone):
    {context_files if context_files else "To pierwszy plik."}
    
    WYMAGANIA:
    1. Zwr√≥ƒá TYLKO kod tego jednego pliku.
    2. Nie u≈ºywaj znacznik√≥w markdown (```python), je≈õli to mo≈ºliwe.
    3. Pamiƒôtaj o importach z plik√≥w, kt√≥re masz w kontek≈õcie.
    """
    
    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=f"Napisz kod dla: {current_filename}")
    ]
    
    response = llm.invoke(messages)
    code = response.content.replace("```python", "").replace("```", "").strip()
    
    # Dodajemy nowy plik do listy
    new_file = {"name": current_filename, "content": code}
    updated_files = existing_files + [new_file]
    
    return {
        "project_files": updated_files,       # Aktualizujemy listƒô plik√≥w
        "current_file_index": idx + 1,        # Przesuwamy licznik dalej
        "messages": [response]
    }